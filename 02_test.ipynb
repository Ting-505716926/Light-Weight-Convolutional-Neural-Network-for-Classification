{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.DataGenerator import load_data\n",
    "from utils.Flops import get_flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型參數設定\n",
    "# MobileNetV3Large、 MobileNetV3Small、CustomizeLarge、 CustomizeSmall, \n",
    "backbone = ['MobileNetV3Large', 'MobileNetV3Small', 'CustomizeLarge', 'CustomizeSmall']\n",
    "backbone = backbone[3]\n",
    "# SE CBAM CA\n",
    "SE_CBAM_CA = 'SE'\n",
    "# Adam RMSprop CLR\n",
    "LR_mode = 'Adam'\n",
    "\n",
    "# 100 Bird Species  or  325 Bird Species  or  cifar100  or  cifar10\n",
    "Dataset = \"325 Bird Species\"\n",
    "BATCH_SIZE = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Dataset == \"325 Bird Species\":\n",
    "    dir = \"./Dataset/325 Bird Species/\"\n",
    "    input_shape = (224,224,3)\n",
    "    num_classes = 325\n",
    "    trainset, valset, testset = load_data(Dataset, dir, input_shape, BATCH_SIZE)\n",
    "    \n",
    "elif Dataset == \"100 Bird Species\":\n",
    "    dir = \"./Dataset/100 Bird Species/\"\n",
    "    input_shape = (224,224,3)\n",
    "    num_classes = 100\n",
    "    trainset, valset, testset = load_data(Dataset, dir, input_shape, BATCH_SIZE)\n",
    "    \n",
    "elif Dataset == \"cifar100\":\n",
    "    input_shape = (32,32,3)\n",
    "    num_classes = 100\n",
    "    datagen_train, datagen_val, x_train, y_train, x_val, y_val, x_test, y_test = load_data(Dataset, '', input_shape, num_classes)\n",
    "    x_train = x_train/255\n",
    "    x_val = x_val/255\n",
    "    x_test =x_test/255\n",
    "    \n",
    "elif Dataset == \"cifar10\":\n",
    "    input_shape = (32,32,3)\n",
    "    num_classes = 10\n",
    "    datagen_train, datagen_val, x_train, y_train, x_val, y_val, x_test, y_test= load_data(Dataset, '', input_shape, num_classes)\n",
    "    x_train = x_train/255\n",
    "    x_val = x_val/255\n",
    "    x_test =x_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Dataset[:5] == 'cifar':\n",
    "    test_generator = x_test\n",
    "    Y_true = y_test\n",
    "    print(np.shape(Y_true))\n",
    "    y_true = np.argmax(Y_true, axis=1)\n",
    "    stepNum=len(test_generator)\n",
    "    print(\"stepNum\",stepNum)\n",
    "else:\n",
    "    # 利用ImageDataGenerator將test樣本讀進來\n",
    "    datagen_test = ImageDataGenerator(rescale= 1/255,)\n",
    "\n",
    "    test_generator = datagen_test.flow_from_directory(dir + 'test',\n",
    "                                                    target_size=(224,224),\n",
    "                                                    batch_size=BATCH_SIZE,\n",
    "                                                    shuffle=False\n",
    "                                                    )\n",
    "    y_true = test_generator.labels\n",
    "    \n",
    "    # test_generator = testset\n",
    "    # y_true = test_generator.labels\n",
    "    \n",
    "    stepNum=len(y_true)\n",
    "    print(\"stepNum\",stepNum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = './weights/{0}/{1}_{2}_{3}/best_model'.format(backbone, SE_CBAM_CA, LR_mode, Dataset)\n",
    "print(model_dir)\n",
    "model = tf.keras.models.load_model(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculation Flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()\n",
    "print(\"The FLOPs is:{}\".format(get_flops(model)) ,flush=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculation FPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_FPS=0\n",
    "num = 5\n",
    "for i in range(num):\n",
    "    start = time.time()\n",
    "\n",
    "    #利用模型進行預測，記得輸入的test_generator的shuffle內建要是False\n",
    "    Y_pred = model.predict(test_generator,steps=stepNum)\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    # Time elapsed\n",
    "    seconds = end - start\n",
    "    FPS = stepNum/seconds\n",
    "    if i==0:\n",
    "        continue\n",
    "    mean_FPS+=FPS\n",
    "    # print(\"FPS:\",FPS)\n",
    "mean_FPS /= num-1\n",
    "print('Mean FPS:',mean_FPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#分類結果，即每個樣本的判斷結果是什麼。例如兩個類別，y_pred就是0與1，且y_pred是(28,)(test樣本數,)的矩陣\n",
    "Y_pred = model.predict(test_generator,steps=stepNum)\n",
    "y_pred = np.argmax(Y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of all classes in CIFAR-100\n",
    "if Dataset=='cifar100':\n",
    "    classes = ['beaver', 'dolphin', 'otter', 'seal', 'whale', \n",
    "    'aquarium' ,'fish', 'ray', 'shark', 'trout', \n",
    "    'orchids', 'poppies', 'roses', 'sunflowers', 'tulips', \n",
    "    'bottles', 'bowls', 'cans', 'cups', 'plates', \n",
    "    'apples', 'mushrooms', 'oranges', 'pears', 'sweet peppers', \n",
    "    'clock', 'computer keyboard', 'lamp', 'telephone', 'television', 'bed', 'chair', 'couch', 'table', 'wardrobe', \n",
    "    'bee', 'beetle', 'butterfly', 'caterpillar', 'cockroach', \n",
    "    'bear', 'leopard', 'lion', 'tiger', 'wolf', \n",
    "    'bridge', 'castle', 'house', 'road', 'skyscraper', \n",
    "    'cloud', 'forest', 'mountain', 'plain', 'sea', \n",
    "    'camel', 'cattle', 'chimpanzee', 'elephant', 'kangaroo', \n",
    "    'fox', 'porcupine', 'possum', 'raccoon', 'skunk', \n",
    "    'crab', 'lobster', 'snail', 'spider', 'worm', \n",
    "    'baby', 'boy', 'girl', 'man', 'woman', \n",
    "    'crocodile', 'dinosaur', 'lizard', 'snake', 'turtle', \n",
    "    'hamster', 'mouse', 'rabbit', 'shrew', 'squirrel', \n",
    "    'maple', 'oak', 'palm', 'pine', 'willow', \n",
    "    'bicycle', 'bus', 'motorcycle', 'pickup truck', 'train', \n",
    "    'lawn-mower', 'rocket', 'streetcar', 'tank', 'tractor']\n",
    "elif Dataset == \"cifar10\":\n",
    "    classes = [\"airplane\", \"automobile\", \"bird\", \"cat\",\n",
    "               \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "else:\n",
    "    brid_pd = pd.read_csv('./Dataset/325 Bird Species/class_dict.csv')\n",
    "    classes = brid_pd['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrixRet=confusion_matrix(y_true = y_true, y_pred= y_pred)\n",
    "\n",
    "fig = plt.figure(figsize=(24,24))\n",
    "ax = fig.add_subplot(211)\n",
    "cax = ax.matshow(confusion_matrixRet)\n",
    "plt.title('Confusion matrix of the classifier')\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels(classes)\n",
    "ax.set_yticklabels(classes)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n",
    "\n",
    "# DF = pd.DataFrame(confusion_matrixRet, columns=classes, index=classes)\n",
    "# DF\n",
    "# DF.to_csv('confusion_matrix.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classification_report, 可以自動算出precision,recall與f1-score\n",
    "classification_reports = classification_report(y_true = y_true,\n",
    "                                               y_pred= y_pred,\n",
    "                                               target_names=classes,\n",
    "                                               output_dict=True)\n",
    "#會輸出precision、recall與f1-score。\n",
    "# print(classification_report(y_true = y_true, y_pred= y_pred, target_names=classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------Method 1-------------------\n",
    "# nn = pd.DataFrame(classification_reports)\n",
    "# nn.T\n",
    "\n",
    "\n",
    "# ---------------Method 2-------------------\n",
    "Dict =  classification_reports\n",
    "Col = []\n",
    "for i in Dict:\n",
    "    Col.append(i)\n",
    "\n",
    "precision=[]\n",
    "recall=[]\n",
    "f1_score=[]\n",
    "support=[]\n",
    "\n",
    "for i in Col:\n",
    "    if i == 'accuracy':\n",
    "        precision.append('')\n",
    "        recall.append('')\n",
    "        f1_score.append(Dict[i])\n",
    "        support.append('')\n",
    "    else:\n",
    "        precision.append(Dict[i]['precision'])\n",
    "        recall.append(Dict[i]['recall'])\n",
    "        f1_score.append(Dict[i]['f1-score'])\n",
    "        support.append(Dict[i]['support'])  \n",
    "\n",
    "Data = {'precision':precision,\n",
    "            'recall': recall,\n",
    "            'f1-score': f1_score,\n",
    "            'support': support}\n",
    "\n",
    "DF = pd.DataFrame(Data,index=Col)\n",
    "# DF.to_csv(\"Accuracy.csv\")\n",
    "DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a480b68b8c343a8999e692c3d6d2f5bf9e4da97c94672fb67f8d413f9dcb69e4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('tf26')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
